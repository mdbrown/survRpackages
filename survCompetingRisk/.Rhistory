dat3$move<-as.numeric(dat3$move)
dat3$ID<-factor(dat3$ID)
dat3.08<-dat3[dat3$Year==2008,]
glm3<-glm(move~ID+Month+Tidal_EFS+Day_Night, data=dat3.08, family=binomial("logit"))
summary(glm3)
setwd("C:/Users/The Browns/Desktop/Consulting/")
load("dat3.Rdata")
names(dat3)
dat3$Month<-factor(dat3$Month)
dat3$Day_Night<-factor(dat3$Day_Night)
dat3$Tidal_EFS<-factor(dat3$Tidal_EFS)
dat3$move<-as.numeric(dat3$move)
dat3$ID<-factor(dat3$ID)
dat3.08<-dat3[dat3$Year==2008,]
glm3<-glm(move~ID+Month+Tidal_EFS+Day_Night, data=dat3.08, family=binomial("logit"))
summary(glm3)
1-pchisq(glm3$deviance, glm3$df.residual)
gee3<-geeglm(move~Tidal_EFS+Day_Night, data=dat3.08, id=ID family=binomial("logit"), corstr="ar1")
library(geeglm)
?gee.control
?glm
?geese.fit
data(dietox)
dietox$Cu     <- as.factor(dietox$Cu)
mf <- formula(Weight~Cu*(Time+I(Time^2)+I(Time^3)))
data("dietox")
data(dietox)
library(geepack)
data(dietox)
dietox$Cu     <- as.factor(dietox$Cu)
mf <- formula(Weight~Cu*(Time+I(Time^2)+I(Time^3)))
dim(dietox)
dietox[1:5,]
gee1 <- geeglm(mf, data=dietox, id=Pig, family=poisson("identity"),corstr="ar1")
gee1
summary(gee1)
mf2 <- formula(Weight~Cu*Time+I(Time^2)+I(Time^3))
gee2 <- geeglm(mf2, data=dietox, id=Pig, family=poisson("identity"),corstr="ar1")
anova(gee2)
ls()
setwd("C:/cygwin/home/The Browns/fhcrc/")
library(MASS)
library(survival)
#load R functions
source("Library.r")
source("NRI.R")
#set global parameters
predict.time=3
n<-500
sim.n<-1000
#set the random seed
set.seed(12321)
output.name<-"sim_output/test_simulation_n1000"
NRI.truevals<-True.NRI.case(1000000)
sim.n<-2
nms<-c("pec.NRI.e", "pec.NRI.ne", "pec.NRI", "pec.Pt",
"cox.NRI.e", "cox.NRI.ne", "cox.NRI", "cox.Pt",
"sth.NRI.e", "sth.NRI.ne", "sth.NRI", "sth.Pt")
#define dataframes to hold the data
#estimates of NRI (under each method, NRI.event, NRI.noevent, NRI, and Pt
est<-as.data.frame(matrix(0, nrow=sim.n, ncol=12))
#standard errors using bootstrap
se<-as.data.frame(matrix(0, nrow=sim.n, ncol=12))
#coverage of true values by a 95% bootstrap CI
cover<-as.data.frame(matrix(0, nrow=sim.n, ncol=12))
names(est)=nms; names(se)=nms; names(cover)=nms
### simulation ###
#perform sim.n simulations
system.time(
for( i in 1:sim.n){
data = SIMDATA.FUN(n)
#Calculate Pt under old (1) and new(2) model
Pt2  = PtfromCox(data,predict.time)
Pt1  = PtfromCox(data[,-c(4)],predict.time)
#estimate NRI using three different estimates
out1 = NRI.pecina(Pt2,Pt1,data,predict.time)
out2 = NRI.cox(Pt2,Pt1)
out3 = NRI.smooth(data[,1], data[,2], predict.time, c(Pt2),Pt1,NULL)
est[i,]<-c(out1, out2, out3)
#bootstrap
boot.dat <- NRI.boot.data(data, bootn=200)
#calculate standard errors
se[i,] <- NRI.boot.se(boot.dat)
#does the bootstrap 95% CI cover the real value?
cover[i,] <- NRI.boot.coverage(boot.dat, NRI.truevals)
}
)
112*500
112*500/60
112*500/(60*60)
est
se
cover
write.table(est, file=paste(output.name, "_est.txt", sep=""), row.names=F, quote=F)
#std errors
write.table(se, file=paste(output.name, "_se.txt", sep=""), row.names=F, quote=F)
#cover
write.table(cover, file=paste(output.name, "_cover.txt", sep=""), row.names=F, quote=F)
citation()
ls()
dat.2<-read.csv("Q_2Data.csv")
names(dat.2)
dat.2$East<-as.factor(dat.2$East)
dat.2$eight<-as.factor(dat.2$eight)
dat.2$North<-factor(as.numeric(dat.2$NS.dist>0))
dat.2$NS.dist<-abs(dat.2$NS.dist)
dir<-NULL
for( i in 1:nrow(dat.2)){
if(dat.2$North[i]==1 & dat.2$East[i]==1){ dir<-c(dir, "NE")}
else if(dat.2$North[i]==1 & dat.2$East[i]==0){ dir<-c(dir, "NW")}
else if(dat.2$North[i]==0 & dat.2$East[i]==1){ dir<-c(dir, "SE")}
else { dir<-c(dir, "SW")}
}
ew<-NULL
for(i in 1:nrow(dat.2)){
if(dat.2$East[i]==1) { ew<-c(ew, "East")}
else {ew<-c(ew, "West")}
}
dat.2$ew<-factor(ew)
dat.2$dir<-factor(dir)
lm2.all<-lm(det.rate~dir*NS.dist, data=dat.2)
summary(lm2.all)
logit<-function( x){}
logit<-function( x){return( log(x/(1-x)))}
names(dat.2)
lm.q2m1<-lm(logit(det.rate)~eight+dir+log(NS.dist), data=dat.2)
lm.q2m1<-lm(logit(det.rate+.01)~eight+dir+log(NS.dist), data=dat.2)
summary(lm.q2m1)
lm.q2m1<-lm(logit(det.rate+1/40)~eight+dir+log(NS.dist), data=dat.2)
summary(lm.q2m1)
lm.q2m4<-lm(logit(det.rate+1/40)~east*log(NS.dist), data=dat.2)
summary(lm.q2m4)
names(dat.2)
lm.q2m4<-lm(logit(det.rate+1/40)~ew*log(NS.dist), data=dat.2)
summary(lm.q2m4)
lm.q2m4<-lm(logit(det.rate+1/40)~East*log(NS.dist), data=dat.2)
summary(lm.q2m4)
?replicate
replicate(5, rnorm(1))
setwd("~/Marshall/work")
source("NRI.R")
source("NRI.R")
library(MASS)
libarary(survival)
libary(survival)
library(survival)
bw.power=.4
predict.time=3
data<-SIMDATA.FUN(100)
NRI.boot(data, c(4), 4)
source("NRI.R")
data<-SIMDATA.FUN(100)
NRI.boot(data, c(4), 4)
Pt2<-PtfromCox(dat[,-c(4)], predict.time)
Pt1<-PtfromCox(dat[,-c(3)], predict.time)
pec<-NRI.pecina(Pt2, Pt1, dat[,c(1:2)], predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(dat[,1], dat[,2], predict.time, c(Pt2), Pt1, NULL)
est<-c(pec, cox, sth)
Pt2<-PtfromCox(dat[,-c(4)], predict.time)
Pt1<-PtfromCox(dat[,-c(3)], predict.time)
pec<-NRI.pecina(Pt2, Pt1, dat[,c(1:2)], predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(dat[,1], dat[,2], predict.time, c(Pt2), Pt1, NULL)
est<-c(pec, cox, sth)
getone.boot<-function(data, ind){
#ind is a vector of the indices of the "new" markers
newdat<-data[sample(1:nrow(data), replace=T),]
Pt2<-PtfromCox(newdat[,], predict.time)
Pt1<-PtfromCox(newdat[,-ind], predict.time)
pec<-NRI.pecina(Pt2, Pt1, newdat[,c(1:2)], predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
est<-c(pec, cox, sth)
est
}
NRI.boot<-function(data, ind, boot.n){
result<-replicate(boot.n, getone.boot( data=data, ind=ind))
result
}
NRI.boot(data, c(4), 4)
NRI.boot<-function(data, ind, boot.n){
result<-replicate(boot.n, getone.boot( data=data, ind=ind))
result
}
newdat<-data[sample(1:nrow(data), replace=T),]
Pt2<-PtfromCox(newdat[,], predict.time)
Pt1<-PtfromCox(newdat[,-ind], predict.time)
ind=c(4)
Pt1<-PtfromCox(newdat[,-ind], predict.time)
pec<-NRI.pecina(Pt2, Pt1, newdat[,c(1:2)], predict.time)
Pt2<-PtfromCox(newdat, predict.time)
Pt1<-PtfromCox(newdat[,-ind], predict.time)
pec<-NRI.pecina(Pt2, Pt1, newdat[,c(1:2)], predict.time)
pec<-NRI.pecina(Pt2, Pt1, newdat, predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
source("Library.R")
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
cox
sth
pec<-NRI.pecina(Pt2, Pt1, newdat, predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
pec<-NRI.pecina(Pt2, Pt1, data=newdat, predict.time)
newdat
dim(newdat)
Pt2
Pt1
pec<-NRI.pecina(Pt2, Pt1, data=newdat, predict.time)
?survfit
PtfromKm = function(data,predict.time) {
km = survfit(Surv(data[,1],data[,2]~1))
1-min(km$surv[km$time<predict.time])
}
pec<-NRI.pecina(Pt2, Pt1, data=newdat, predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
PtfromKm = function(data,predict.time) {
km = survfit(Surv(data[,1],data[,2])~1)
1-min(km$surv[km$time<predict.time])
}
pec<-NRI.pecina(Pt2, Pt1, data=newdat, predict.time)
cox<-NRI.cox(Pt2, Pt1)
sth<-NRI.smooth(newdat[,1], newdat[,2], predict.time, c(Pt2), Pt1, NULL)
pec
cox
sth
NRI.boot(data, ind=c(4), 5)
NRI.boot<-function(data, ind, boot.n){
result<-replicate(boot.n, getone.boot( data=data, ind=ind))
return( apply(result, 1, sd))
}
NRI.boot(data, ind=c(4), 5)
NRI.boot(data, ind=c(4), 50)
?quantile
getone.cover<-function( estimates, trueval){
##estimates is a vector of estimates across different bootstrap samples of the same data
result<-ifelse(quantile(estimates, .025)<trueval & trueval<quantile(estimates,.975), 1, 0)
result
}
?mapply
result
data
list(data)
split(data,colnames(data))
colnames(data)
data
?split
split(data,col)
split(data,data[,i])
split(data)
as.data.frame(data)
col.names(as.data.frame(data))
colnames(as.data.frame(data))
split(as.data.frame(data), )
#perform the bootstrap
NRI.boot<-function(data, ind, boot.n, truevals){
result<-as.data.frame(replicate(boot.n, getone.boot( data=data, ind=ind)))
#find the coverage of the estimates
cover<-mapply(getone.cover, split(result, colnames(result)), truevals )
return( list("se"=apply(result, 1, sd), "coverage"=)
}
NRI.boot<-function(data, ind, boot.n, truevals){
result<-as.data.frame(replicate(boot.n, getone.boot( data=data, ind=ind)))
#find the coverage of the estimates
cover<-mapply(getone.cover, split(result, colnames(result)), truevals )
return( list("se"=apply(result, 1, sd), "coverage"=))
}
#perform the bootstrap
NRI.boot<-function(data, ind, boot.n, truevals){
result<-as.data.frame(replicate(boot.n, getone.boot( data=data, ind=ind)))
#find the coverage of the estimates
cover<-mapply(getone.cover, split(result, colnames(result)), truevals )
return( list("se"=apply(result, 1, sd), "coverage"=cover))
}
NRI.boot(data, c(4), 5, c(.5,.5,0,.6))
boot.n=5
ind
result<-as.data.frame(replicate(boot.n, getone.boot( data=data, ind=ind)))
result
cover<-mapply(getone.cover, split(result, rownames(result)), truevals )
trueval=c(.5,.5,0,.6)
truevals=c(.5,.5,0,.6)
cover<-mapply(getone.cover, split(result, rownames(result)), truevals )
cover
#perform the bootstrap
NRI.boot<-function(data, ind, boot.n, truevals){
result<-as.data.frame(replicate(boot.n, getone.boot( data=data, ind=ind)))
#find the coverage of the estimates
cover<-mapply(getone.cover, split(result, rownames(result)), truevals )
return( list("se"=apply(result, 1, sd), "coverage"=cover))
}
NRI.boot(data, c(4), 5, c(.5, .5, 0, .6))
sample(1:10, 4)
replicate(sample(1:10,4),4)
replicate(4,sample(1:10,4))
rep(0,10)
I(5)
diag(10)
SIMDATA.FUN.CV<-function(n) {
Y=mvrnorm(n,rep(0,10),diag(10))
#ten markers, only two have nonzero betas
beta=c(log(3),log(2),rep(0,8))
mu.i<-Y%*%beta
stime<--mu.i+log(-log(runif(n)))
stime<-10*exp(stime)
cuttime<-5
ctime<-runif(n,0,cuttime)
times = pmin(stime,ctime)
status = ifelse(stime<=ctime,1,0)
data = cbind(times,status,Y)
data
}
data<-SIMDATA.FUN.CV(500)
table(data[,2])
table(data[,2])
table(data[,2])/500
#simulate the data
SIMDATA.FUN.CV<-function(n) {
Y=mvrnorm(n,rep(0,10),diag(10))
#ten markers, only two have nonzero betas
beta=c(log(3),log(2),rep(0,8))
mu.i<-Y%*%beta
stime<--mu.i+log(-log(runif(n)))
stime<-10*exp(stime)
cuttime<-20
ctime<-runif(n,0,cuttime)
times = pmin(stime,ctime)
status = ifelse(stime<=ctime,1,0)
data = cbind(times,status,Y)
data
}
data<-SIMDATA.FUN.CV(1000)
table(data[,2])/1000
data<-SIMDATA.FUN(1000)
table(data[,2])/1000
#simulate the data
SIMDATA.FUN.CV<-function(n) {
Y=mvrnorm(n,rep(0,10),diag(10))
#ten markers, only two have nonzero betas
beta=c(log(3),log(2),rep(0,8))
mu.i<-Y%*%beta
stime<--mu.i+log(-log(runif(n)))
stime<-10*exp(stime)
cuttime<-25
ctime<-runif(n,0,cuttime)
times = pmin(stime,ctime)
status = ifelse(stime<=ctime,1,0)
data = cbind(times,status,Y)
data
}
data<-SIMDATA.FUN.CV(1000)
table(data[,2])/1000
SIMDATA.FUN.CV<-function(n) {
Y=mvrnorm(n,rep(0,10),diag(10))
#ten markers, only two have nonzero betas
beta=c(log(3),log(1.5),rep(0,8))
mu.i<-Y%*%beta
stime<--mu.i+log(-log(runif(n)))
stime<-10*exp(stime)
cuttime<-25
ctime<-runif(n,0,cuttime)
times = pmin(stime,ctime)
status = ifelse(stime<=ctime,1,0)
data = cbind(times,status,Y)
data
}
data<-SIMDATA.FUN.CV(5000)
table(data[,2])/5000
targets = c( 0.004737948, 0.009135707, 0.011528195, 0.012915749, 0.013848084,0.014517128,
0.015007801, 0.015366664, 0.015650859, 0.015850504, 0.016018583, 0.016152996,
0.016239272, 0.016344997, 0.001266110, 0.002899116, 0.003769963, 0.010517575,
0.006389022, 0.007528527)
SD.vec <- c(.1, seq(from = .5, to = 6, by =.5))#collect all of the data
SD.vec2 <- c(0.006, 0.034, 0.06, 0.75, 0.2, 0.3, 7)
SD.vec <- c(SD.vec, SD.vec2)
ooo <- order(SD.vec)
SD.vec <- SD.vec[ooo]
targets <- targets[ooo]
targets
SD.vec
cbind(targets, SD.vec)
for( b in seq(from = .1, to = 20, by = .1))
{}
mys <- seq(from = .1, to = 20, by  = .1)
mycol <- rainbow(length(mys))
for( b in mys) {}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 10))
i = 0
for(b in myseq){}
for(b in myseq){
i = i+1
lines(dbeta(1:100/100, b, b), col = mycol[i])
}
for(b in mys){
i = i+1
lines(dbeta(1:100/100, b, b), col = mycol[i])
}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 10))
for(b in mys){
i = i+1
}
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, b, b), col = mycol[i])
}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 6))
for(b in mys){
+ i = i+1
+ lines(dbeta(1:100/100, b, 2*b), col = mycol[i])
+ }
for(b in mys){
+ i = i+1
+ lines(dbeta(1:100/100, b, 2*b), col = mycol[i])
+ }
for(b in mys){
i = i+1
lines(dbeta(1:100/100, b, 2*b), col = mycol[i])
}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 6))
for(b in mys){
}
i = 0
i = 0
for(b in mys){
i = i+1
lines(dbeta(1:100/100, b, b), col = mycol[i])
}
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, b, b), col = mycol[i])
}
source('~/.active-rstudio-document', echo=TRUE)
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, 2*b, b), col = mycol[i])
}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 6))
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, 2*b, b), col = mycol[i])
}
plot(c(0,0), type = "n", xlim = c(0,1), ylim = c(0, 8))
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, 2*b, b), col = mycol[i])
}
i = 0
for(b in mys){
i = i+1
lines(1:100/100, dbeta(1:100/100, b, 2*b), col = mycol[i])
}
install.packages("GitHub/survRpackages/survNRI_0.1.zip")
library(survNRI)
data(SimData)
?survNRI
sessionInfo()
setwd("GitHub/survRpackages/")
install.packages("survNRI_0.1.zip")
library(survNRI)
library(survNRI)
data(SimData)
x<- survNRI( time  = "stime", event = "status", model1 = "y1", model2 = c("y1", "y2"), data = SimData,
predict.time = 2, method = c("SmoothIPW", "SEM", "Combined"), bootMethod = "percentile", bootstraps = 10)
x
survNRI( time  = "stime", event = "status", model1 = "y1", model2 = c("y1", "y2"), data = SimData,
predict.time = 2, method = "all", bootstraps = 100, alpha = .01)
?survNRI
survNRI( time  = "stime", event = "status", model1 = "y1", model2 = c("y1", "y2"), data = SimData,
predict.time = 2, method = "all", bootMethod = "normal",  bootstraps = 25, alpha = .01)
library(knitr)
library(Knitr)
install.packages("knitr")
?survNRI
install.packages("survAccuracyMeasures_1.0.zip")
setwd("survAccuracyMeasures/")
?survEstMeasuresw
?survEstMeasures
library(survAccuracyMeasures)
?survEstMeasures
data(SimData)
tmp <- survEstMeasures(time =SimData$survTime, event = SimData$status, marker = SimData$Y, predict.time = 2, measures = c("AUC", "TPR"), SEmethod = 'bootstrap', bootstraps = 50, cutpoint = 0)
tmp
tmp$estimates
tmp$CIbounds
runGitHub("shiny_example", "rstudio")
library(shiny)
install.packages("shiny")
library(shiny)
runGitHub("shiny_example", "rstudio")
setwd("../survCompetingRisk/")
install.packages("../survCompetingRisk_1.0.zip")
?survCompetingRisk
help(survCompetingRisk)
vignette(survCompetingRisk)
vignettes(survCompetingRisk)
vignette("survCompetingRisk")
?survCompetingRisk-package
?CompetingRisk-package
?CompetingRisk
install.packages("../survCompetingRisk_1.1.zip")
library(survCompetingRisk)
sessionInfo()
?survCompetingRisk
?comprisk.ROC
?comprisk.ROC.CI
